{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 평가\n",
    "\n",
    "### 분류 모델의 평가 지표\n",
    ": 예측 대상이 범주형 데이터 경우\n",
    "- 정확도(Accuracy)\n",
    "- 재현율(Recall)\n",
    "- 정밀도(Precision)\n",
    "- F1 measure\n",
    "- G measure\n",
    "- ROC curve\n",
    "- AUC\n",
    "\n",
    "### 회귀 모델의 평가 지표\n",
    ": 예측 대상이 수치 데이터인 경우\n",
    "- MSE(Mean Square Error)\n",
    "- RMSE(Root Mean Square Error)\n",
    "- MAE(Mean Absolute Error)\n",
    "- MAPE(Mean Absolute Percentage Error)\n",
    "- $ R^2 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "# # 분류 모델의 성능 평가 지표\n",
    "\n",
    "# ## Accuracy(정확도)\n",
    "\n",
    "# - 실제 데이터와 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "# \n",
    "# - $ 정확도(Accuracy) =  \\frac{예측 결과가 동일한 데이터 건수}{전체 예측 데이터 건수} $\n",
    "# \n",
    "# \n",
    "# - 직관적으로 모델 예측 성능을 나타내는 평가 지표\n",
    "# - 그러나 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 \n",
    "#     - 정확도 수치 하나만 가지고 성능을 평가하지는 않음\n",
    "# \n",
    "# \n",
    "# - 특히 정확도는 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 지표가 아님\n",
    "\n",
    "# ### 정확도 문제 예\n",
    "# 1. 타이타닉 생존자 예측\n",
    "# 2. MNIST 데이터 세트 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 모델의 성능 평가 지표\n",
    "\n",
    "## Accuracy(정확도)\n",
    "\n",
    "- 실제 데이터와 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "\n",
    "- $ 정확도(Accuracy) =  \\frac{예측 결과가 동일한 데이터 건수}{전체 예측 데이터 건수} $\n",
    "\n",
    "\n",
    "- 직관적으로 모델 예측 성능을 나타내는 평가 지표\n",
    "- 그러나 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 \n",
    "    - 정확도 수치 하나만 가지고 성능을 평가하지는 않음\n",
    "\n",
    "\n",
    "- 특히 정확도는 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 지표가 아님\n",
    "\n",
    "### 정확도 문제 예\n",
    "1. 타이타닉 생존자 예측\n",
    "2. MNIST 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# 아무런 학습을 하지 않고 성별에 따라 생존자를 예측하는 \n",
    "# 단순한 Classifier 생성\n",
    "# BaseEstimator 상속 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음.\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyDummyClassifier를 이용해 타이타닉 생존자 예측 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가공 (타이타닉 생존자 예측 시 작성)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 생존자 예측 \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('data/titanic_train.csv')\n",
    "\n",
    "# 결정값\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "# 학습 데이터 세트\n",
    "# 결정값으로 사용할 'Survived' 칼럼 제외\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "mypred = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MNIST 데이터 세트\n",
    "* 0~9까지의 숫자 이미지의 픽셀 정보를 가지고 있고\n",
    "* 이를 기반으로 숫자 Digit을 예측하는 데 사용\n",
    "* 사이킷런의 load_digits() API를 통해 MNIST 데이터 세트 제공\n",
    "\n",
    "**이진 분류 문제로 변환**\n",
    "* 불균형한 데이터 세트로 변형\n",
    "* 레이블 값이 7인 것만 True, 나머지 값은 모두 False로 변환\n",
    "* True : 전체 데이터의 10%\n",
    "* False : 90%\n",
    "    \n",
    "**입력되는 모든 데이터를 False, 즉 0으로 예측하는 classifier를 이용해**\n",
    "* 정확도를 측정하면 약 90%에 가까운 예측 정확도를 나타냄\n",
    "\n",
    "### 정확도 평가 지표의 맹점\n",
    "* 아무것도 하지 않고 무조건 특정한 결과로 찍어도\n",
    "* 데이터가 균일하지 않은 경우 높은 수치가 나타날 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**digit 데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7인 데이터 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7인 데이터는 1, 그외 데이터는 0으로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, \n",
    "# 7번이 아니면 False이고 0으로 변환. \n",
    "y = (digits.target == 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습 / 테스트 데이터 세트로 분리 (default = 0.25))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 / 테스트 데이터 세트로 분리 (default = 0.25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  3., ..., 12., 14.,  7.],\n",
       "       [ 0.,  1.,  9., ..., 10.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ..., 16., 13.,  1.],\n",
       "       [ 0.,  1., 11., ..., 13., 16.,  5.],\n",
       "       [ 0.,  0.,  6., ...,  6.,  0.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  7., ...,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  1., 13., ..., 15.,  3.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 12.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**불균형한 레이블 데이터 분포도 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test.shape :  (450,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    405\n",
       "1     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print(\"y_test.shape : \" , y_test.shape)\n",
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "\n",
    "fake_cl = MyFakeClassifier()\n",
    "fake_cl.fit(X_train, y_train)\n",
    "fakePred = fake_cl.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, fakePred)\n",
    "print('정확도 : ', np.round((accuracy), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix (오차 행렬)\n",
    "\n",
    "오차행렬 (Confusion Matrix : 혼동행렬)\n",
    "* 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표\n",
    "* 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고(confused) 있는지도 함께 보여주는 지표\n",
    "* 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 가지고 맵핑되는지 나타냄\n",
    "* 예측 클래스와 실제 클래스의 값 유형에 따라 TN, FP, FN, TP 형태\n",
    "* TN, FP, FN, TP 값을 다양하게 결합해 분류 모델 예측 성능의 오류가 어떤 모습으로 발생하는지 알 수 있음\n",
    "\n",
    "TN, FP, FN, TP는 예측 클래스와 실제 클래스의 \n",
    "* Positive 결정값(1)과 Negative 결정값(0)의 결합에 따라 결정\n",
    "* 앞 문자 T/F(True/False) : 예측값과 실제값이 '같은가/틀린가' 의미\n",
    "* 뒤 문자 N/P(Negative/Positive) : 예측 결과 값이 부정(0)/긍정(1) 의미\n",
    "* 예 : TN (True Negative) \n",
    "    - 앞 True : 예측 클래스 값과 실제 클래스 값이 같다는 의미\n",
    "    - 뒤 Negative : 예측 값이 Negative 값이라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# MNISt의 fakepred\n",
    "confusion_matrix(y_test, fakePred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과  \n",
    "[[TN, FP],  \n",
    " [FN, TP]]\n",
    "\n",
    "MyFakeClassifier는 load_digits()에서 target=7인지 아닌지에 따라  \n",
    "클래스 값을 True/False 이진 분류로 변경한 데이터 세트를 사용해서  \n",
    "무조건 Negative로 예측하는 Classifier였고  \n",
    "테스트 데이터 세트의 클래스 값 분포는 0이 450건, 1이 45건 이었음  \n",
    "\n",
    "* TN : 전체 450건 데이터 중 무조건 Negative 0으로 예측해서 True가 된 결과 450건\n",
    "    - 실제값/예측값 동일, Negative로 예측  \n",
    "* FP : Positive 1로 예측한 건수가 없으므로 0건\n",
    "    - 실제값/예측값 다름, Positive로 예측  \n",
    "* FN : Positive 1인 건수 45건을  Negative 0으로 예측해서 False가 된 결과 45건\n",
    "    - 실제값/예측값 다름, Negative로 예측  \n",
    "* TP : Positive 1로 예측한 건수가 없으므로 0건\n",
    "    - 실제값/예측값 동일, Positive로 예측  \n",
    "\n",
    "**TN, FP, FN, TP 값은 Classifier 성능의 여러 면모를 판단할 수 있는 기반 정보 제공**\n",
    "- 이 값을 조합해 Classifier의 성능을 측정할 수 있는 주요 지표인 정확도(Accuracy), 정밀도(Predision), 재현율(Recall) 값을 알 수 있음\n",
    "\n",
    "### 오차행렬 상에서 정확도\n",
    "\n",
    "* 정확도(Accuracy) = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수\n",
    "\n",
    "    $ = \\frac{TN + TP}{ TN + FP + FN + TP }$\n",
    "\n",
    "### 불균형한 이진 분류 모델 \n",
    "\n",
    "* 많은 데이터 중에서 중점적으로 찾아야 하는 매우 적은 수의 결과 값에 Positive를 설정해 1 값을 부여하고\n",
    "* 그렇지 않은 경우는 Negative로 0을 부여하는 경우가 많음  \n",
    "\n",
    "예1: 사기 행위 예측 모델\n",
    "* 사기 행위 : Positive 양성으로 1\n",
    "* 정상 행위 : Negative 음성으로 0  \n",
    "    \n",
    "예2 : 암 검진 예측 모델\n",
    "* 양성 : Positive 양성으로 1\n",
    "* 음성 : Negative 음성으로 0 \n",
    "\n",
    "### 불균형한 이진 분류 데이터 세트에서 정확도의 맹점\n",
    "\n",
    "**Positive 데이터 건수가 매우 작아서 Positive 보다는 Negative로 예측 정확도가 높아지는 경향이 발생**  \n",
    "\n",
    "- 10,000 건의 데이터 세트에서 9,900 건이 Negative이고 100건이 Positive라면 Negative로 예측하는 경향이 더 강해져서 TN은 매우 커지고 TP는 매우 작아지게 됨  \n",
    "\n",
    "- 또한 Negative로 예측할 때 정확도가 높기 때문에 FN(Negative로 예측할 때 틀린 데이터 수)이 매우 작고, Positive로 예측하는 경우가 작기 때문에 FP 역시 매우 작아짐  \n",
    "\n",
    "- 정확도 지표는 비대칭한 데이터 세트에서 Positive에 대한 예측 정확도를 판단하지 못한 채 Negative에 대한 예측 정확도만으로도 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게 됨  \n",
    "\n",
    "\n",
    "**불균형한 데이터 세트에서 정확도보다 더 선호되는 평가 지표**\n",
    "- 정밀도(Predision)와 재현율(Recall) \n",
    "\n",
    "# 정밀도(Precision)와 재현율(Recall)\n",
    "\n",
    "### 정밀도(Predision)와 재현율(Recall)\n",
    "* Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표\n",
    "* 앞의 MyFakeClassifier는 Positive로 예측한 TP값이 하나도 없기 때문에\n",
    "* 정밀도와 재현율 값이 모두 0\n",
    "\n",
    "**정밀도와 재현율 계산 공식**\n",
    "* 정밀도 = TP / (FP + TP)\n",
    "* 재현율 = TP / (FN + TP)\n",
    "\n",
    "\n",
    "### 정밀도 : TP / (FP + TP)\n",
    "* 예측을 Positive로 한 대상 중에 \n",
    "* 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "* 예측한 양성 대 예측한(맞춘) 양성\n",
    "* 공식의 분모인 (FP + TP)는 예측을 Positive로 한 모든 데이터 건수 (예측한 양성)\n",
    "* 분자인 TP는 예측과 실제 값이 Positive로 일치한 데이터 건수 (맞춘 양성)\n",
    "* Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 \n",
    "* 양성 예측도라고도 불림\n",
    "\n",
    "### 재현율 : TP / (FN + TP)\n",
    "* 실제값이 Positive인 대상 중에\n",
    "* 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "* 실제 양성 대 예측한(맞춘) 양성 비율\n",
    "* 공식의 분모인 (FN + TP)는 실제값이 Positive인 모든 데이터 건수 (실제 양성)\n",
    "* 분자인 TP는 예측과 실제 값이 Positive로 일치한 데이터 건수 (맞춘 양성)\n",
    "* 민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불림\n",
    "\n",
    "보통은 재현율이 정밀도보다 상대적으로 중요한 업무가 많지만  \n",
    "정밀도가 더 중요한 지표인 경우도 있음\n",
    "\n",
    "예: 스팸메일 여부를 판단하는 모델\n",
    "* 실제 Positive인 스팸메일을 Negative인 일반 메일로 분류하더라도\n",
    "* 사용자가 불편함을 느끼는 정도이지만\n",
    "* 실제 Negative인 일반 메일을 Positive인 스팸 메일로 분류할 경우\n",
    "* 메일을 아예 받지 못하게 되어 업무에 차질이 생길 수 있음\n",
    "\n",
    "**재현율이 상대적으로 더 중요한 지표인 경우**\n",
    "* 실제 Positive 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 \n",
    "* 업무상 큰 영향이 발생하는 경우\n",
    "\n",
    "**정밀도가 상대적으로 더 중요한 지표인 경우**\n",
    "* 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면\n",
    "* 업무상 큰 영향이 발생하는 경우\n",
    "\n",
    "### 재현율과 정밀도의 보완적 관계\n",
    "* 재현율과 정밀도 모두 TP를 높이는 데 동일하게 초점을 맞춤\n",
    "\n",
    "\n",
    "* 재현율은 FN(실제 Positive, 예측 Negative)를 낮추는데 초점을 맞추고\n",
    "* 정밀도는 FP를 낮추는데 초점을 맞춤\n",
    "\n",
    "\n",
    "* 재현율과 정밀도는 서로 보완적인 지표로 분류의 성능을 평가하는데 적용\n",
    "* 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것\n",
    "* 반면에 둘 중 어느 한 평가 지표만 매우 높고, 다른 수치는 매우 낮은 결과를 나타내는 경우는 바람직하지 않음\n",
    "\n",
    "### MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정\n",
    "\n",
    "타이타닉 예제로 오차 행렬 및 정밀도, 재현율 구해서 예측 성능 평가\n",
    "* 사이킷런 API 사용\n",
    "    - 정밀도 계산 : precision_score() \n",
    "    - 재현율 계산 : recall_score()\n",
    "    - 오차행렬 : confusion_matrix()\n",
    "\n",
    "평가 간편 적용하기 위한 함수 작성\n",
    "* confusion_matrix / precision / recall 등의 평가를 한꺼번에 호출 \n",
    "\n",
    "타이타닉 데이터를 로지스틱 회귀로 분류 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도와 재현율 계산에 사용되는 예측값\n",
    "# 앞에서 Dummy Classifier로 학습후 예측한 값 : fakepred\n",
    "# (앞에 다 있는 내용인데 흩어져 있어서\n",
    "# 정밀도와 재현율 계산을 위해 다시 모아서 적음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (digits.target == 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_clf=MyFakeClassifier()\n",
    "fake_clf.fit(X_train, y_train)\n",
    "fakepred = fake_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fakepred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고 : fakepred 값 확인 \n",
    "# fakepred # (모두 False)\n",
    "fakepred.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 : 0.0\n",
      "재현율 : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhm05\\anaconda3\\envs\\multi\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 정밀도와 재현율 계산\n",
    "# 정밀도 계산 : precision_score(실제값, 예측값)\n",
    "# 재현율 계산 : recall_score(실제값, 예측값)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print('정밀도 :', precision_score(y_test, fakepred))\n",
    "print('재현율 :', recall_score(y_test, fakepred))\n",
    "\n",
    "# `zero_division` : 분모가 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)  # 오차행렬\n",
    "    accuracy = accuracy_score(y_test, pred)     # 정확도\n",
    "    precision = precision_score(y_test, pred)    # 정밀도\n",
    "    recall = recall_score(y_test, pred)         # 재현율\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.3f}, 정밀도: {1:.3f}, 재현율: {2:.3f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**앞의 타이타닉 데이터 세트 전처리 작업 내**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터 세트 전처리 작업 내용 (앞에서 했음)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 기반으로\n",
    "# 타이타닉 생존자 예측하고\n",
    "# confusion matrix, accuracy, precision, recall 평가 수행\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,                                                     test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# lr_clf.fit(X_train , y_train)\n",
    "# pred = lr_clf.predict(X_test)\n",
    "# get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/Recall Trade-off\n",
    "\n",
    "\n",
    "**정밀도 / 재현율 트레이드 오프(Trade-off)**\n",
    "* 업무에 따라 정밀도/재현율 중요도 다름\n",
    "* 분류하려는 업무 특성상 정밀도 또는 재현율이 특별히 강조돼야 할 경우\n",
    "* 분류의 결정 임계값(Threshold)을 조정해서 정밀도 또는 재현율의 수치를 높일 수 있음\n",
    "\n",
    "* 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지는데 이를 정밀도/재현율의 트레이드 오프라고 함\n",
    "\n",
    "### predict_proba( ) 메소드\n",
    "\n",
    "타이타닉 생존자 데이터를 학습한 LogisticRegression 객체에서  \n",
    "predict_proba() 메서드를 수행한 뒤 반환 값 확인하고  \n",
    "predict() 메서드와 결과 비교  \n",
    "앞 예제에 이어서 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_clf = LogisticRegression()\n",
    "# predict_proba(테스트 피처 데이터 세트) : 예측 확률 반환\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred_proba[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba() 결과 설명 : 예측 확률 array  \n",
    "첫 번째 칼럼은 0 Negative의 확률  \n",
    "두 번째 칼럼은 1 Positive의 확률  \n",
    "반환 결과인 ndarray는 0과 1에 대한 확률을 나타내므로  \n",
    "첫 번째 칼럼 값과 두 번재 칼럼 값을 더하면 1이 됨  \n",
    "[0.46162417 + 0.53837583] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(테스트 피처 데이터 세트) : 예측 결과 클래스 값 반환\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측')\n",
    "print(pred_proba_result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 타이타닉  생존자 데이터에서 predict() 결과 값과 predict_proba() 결과 값을 비교\n",
    "# pred_proba = lr_clf.predict_proba(X_test)\n",
    "# pred = lr_clf.predict(X_test)\n",
    "\n",
    "# print('pred_proba의 shape: {0}'.format(pred_proba.shape))\n",
    "# print('pred_proba의 array에서 앞 3개만 샘플로 추출 :\\n', pred_proba[:3])\n",
    "\n",
    "# #예측확률 array와 예측 결과값 array를 병합하여 예측확률과 결괏값을 한 번에 확인\n",
    "# pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "# print('두 개의 class 중 더 큰 확률을 클래스 값으로 예측\\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizer 클래스 활용\n",
    "\n",
    "사이킷런의 Binarizer 클래스 이용해서  \n",
    "분류 결정 임계값을 조절하여  \n",
    "정밀도와 재현율의 성능 수치를 상호 보완적으로 조정 가능\n",
    "\n",
    "Binarizer 클래스 이용 예측값 변환 예제\n",
    "* threshold 변수를 특정 값으로 설정하고\n",
    "* Binarizer 클래스의 fit_transform() 메서드를 이용해서\n",
    "* 넘파이 ndarray 입력 값을 지정된 threshold보다 같거나 작으면 0 값으로,\n",
    "* 크면 1값으로 변환해서 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[ 0.5, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.0)                     \n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임계값 = 0.5로 설정.  \n",
    "c_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값([0확률 1확률])의 두번째 컬럼 , \n",
    "# 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "bina = Binarizer(threshold=c_threshold).fit(pred_proba_1) \n",
    "custom_predict = bina.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "# 앞에서 predict()로 구한 결과와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**분류 결정 임계값을 0.4로 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_threshold = 0.4\n",
    "\n",
    "# predict_proba( ) 반환값([0확률 1확률])의 두번째 컬럼 , \n",
    "# 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "# 임계값을 낮추니까 정밀도는 떨어지고 재현율 값은 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )\n",
    "\n",
    "# 정밀도 / 재현율 트레이드 오프 \n",
    "# - 한 쪽을 향상시키면 다른 수치 감소하니까 적당한 수치 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임곗값에 따른 정밀도-재현율 값 추출\n",
    "- precision_recall_curve( ) 를 이용\n",
    "\n",
    "**precision_recall_curve( 실제값, 레이블 값이 1일 때의 예측 확률값)**\n",
    "- 정밀도, 재현율, 임계값을 ndarray로 반환\n",
    "- 임계값 : 일반적으로 0.11~0.95 범위\n",
    "- 정밀도와 재현율의 임계값에 따른 값 변화를 곡선 형태의 그래프로 시각화하는데 이용\n",
    "\n",
    "### 예제\n",
    "- 반환되는 임계값이 너무 작은 값 단위로 많이 구성되어 있음\n",
    "- 반환된 임계값의 데이터 143건(교재 147건)인데\n",
    "- 임계값을 15단계로 해서 샘플로 10건만 추출\n",
    "- 좀 더 큰 값의 임계값과 그때의 정밀도와 재현율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('임계값 shape: ', thresholds.shape)\n",
    "print('정밀도 shape: ', precisions.shape)\n",
    "print('재현율 shape: ', recalls.shape)\n",
    "\n",
    "idx = np.arange(0, thresholds.shape[0], 15)\n",
    "print('sample index:', idx)\n",
    "print('임계값 sample: ', np.round(thresholds[idx], 3))\n",
    "print('정밀도 sample: ', np.round(precisions[idx], 3))\n",
    "print('재현율 sample: ', np.round(recalls[idx], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#반환된 임계값 배열 행이 143건으로\n",
    "# 임계값을 15단계로 해서 샘플로 10건만 추출\n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임곗값의 변경에 따른 정밀도-재현율 변화 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# y_test : 실제 값  pred_proba_c1: 예측 확률 값\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1): \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0] # (143,)에서 143 추출\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision') \n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    " \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "정밀도와 재현율 조합\n",
    "- Positive 예측의 임계값에 따라 정밀도와 재현율 수치가 변경\n",
    "- 임계값은 업무 환경에 맞게 정밀도와 재현율의 수치를 상호 보완할 수 있는 수준에서 적용되어야 함\n",
    "- 단순히 하나의 성능 지표 수치를 높이기 위한 수단으로 사용돼서는 안 됨\n",
    "\n",
    "분류의 종합적인 성능 평가에 사용하기 위해서는  \n",
    "정밀도와 재현율의 수치를 적절하게 조합하는 것이 필요함\n",
    "\n",
    "# F1 Score\n",
    "\n",
    "### F1 Score\n",
    "- 정밀도와 재현율의 조화평균\n",
    "- 정밀도와 재현율이 어느 한족으로 치우치지 않는 수치를 나타낼때 상대적으로 높은 값을 가짐\n",
    "\n",
    "### F1 Score 공식\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "### 예 : 두 예측 모델 비교  \n",
    "A 예측 모델\n",
    "- 정밀도 : 0.9\n",
    "- 재현율 : 0.1 (극단적 차이)\n",
    "- F1 스코어 : 0.18\n",
    "\n",
    "B 예측 모델\n",
    "- 정밀도 : 0.5\n",
    "- 재현율 : 0.5 (큰 차이 없음)\n",
    "- F1 스코어 : 0.5 \n",
    "\n",
    "B모델의 FI 스코어가 A모델에 비해 매우 우수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의 F1 스코어 API : f1_score()\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 생존자 예측에서 F1 스코어\n",
    "- 임계값을 변화시키면서 F1 스코어를 포함한 평가 지표 구하기\n",
    "- 임계값 0.4~0.6별로 정확도, 정밀도, 재현율, F1 스코어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    \n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'\n",
    "          .format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 0.4~0.6별로 정확도, 정밀도, 재현율, F1 스코어 확인\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G measure\n",
    "\n",
    "- 정밀도와 재현율의 기하평균\n",
    "\n",
    "- $ G = \\sqrt{Precision × Recall}$\n",
    "\n",
    "# ROC Curve와 AUC\n",
    "\n",
    "### ROC(Reciver Operating Characteristic)\n",
    "\n",
    "- 수신자 판단 곡선\n",
    "- 2차대전 때 통신장비 성능평가를 위해 고안된 척도\n",
    "- 의학분야에서 많이 사용\n",
    "- ML의 이진분류 모델의 예측 성능의 중요 평가지표\n",
    "\n",
    "\n",
    "- FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)가 어떻게 변하는지를 나타내는 곡선\n",
    "    - FPR이 X축, TPR이 Y축\n",
    "    \n",
    "\n",
    "- TPR : 재현율과 같으며, 민감도(Sensitivity)라 부름\n",
    "    - 실제값 Positive(양성)가 정확히 예측되어야 하는 수준\n",
    "        - 질병이 있는 사람이 질병이 있는 것(양성)으로 판정 \n",
    "        \n",
    "- FPR : 1-특이성(Specificity)\n",
    "    - 질병이 없는 건강한 사람이 질병이 있는 것으로 예측되는 수준\n",
    "    - 특이성 : 실제값 Negative(음성)가 정확히 예측되어야 하는 수준\n",
    "        - 질병이 없는 건강한 사람은 질병이 없는 것(음성)으로 판정 \n",
    "\n",
    "- FPR은 0부터 1까지 변경하면서 TPR의 변화 값을 구함\n",
    "    - 분류 결정 임계값(Positive 예측값을 결정하는 기준)을 변경하면서 결정\n",
    "    \n",
    "    \n",
    "- FPR을 0으로 만들려면 분류 결정 임계값을 1로 지정\n",
    "    - Positive 예측 기준이 높아 데이터를 Positive로 예측할 수 없음\n",
    "    - FPR이 0인 경우 Positive를 예측할 수 없어 FPR이 0이 됨\n",
    "    \n",
    "    \n",
    "- FPR을 1로 만들려면 분류 결정 임계값을 0으로 지정하여 TN을 0으로 만들면 됨\n",
    "    - 분류기의 Positive 확률기준이 너무 낮아 다 Positive로 예측\n",
    "    - Negative를 예측할 수 없으므로 TN이 0이 되고 FPR은 1이 됨\n",
    "\n",
    "    \n",
    "https://hsm-edu.tistory.com/1033\n",
    "\n",
    "### AUC(Area Under the Curve)\n",
    "- ROC 곡선 아래 면적\n",
    "- 대각선의 직선에 대응되면 AUC는 0.5\n",
    "- 1에 가까울수록 좋은 수치\n",
    "- FPR이 작을 때 얼마나 큰 TPR을 얻는지에 따라 결정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정되는데\n",
    "# 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "\n",
    "print('샘플 추출을 위한 임곗값 배열의 index :', thr_index)\n",
    "print('샘플용 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "# 교재에서는 10개. 실제 11개\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test, pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음\n",
    "    fprs, tprs, thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs, tprs, label='ROC')\n",
    "    \n",
    "    # 가운데 대각선 직선을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Specificity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 생존자 예측 로지스틱 회귀 모델의 ROC AUC 값 확인\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_clf_eval() 변경 \n",
    "# ROC-AUC 추가 : 예측 확률값을 기반으로 계산되므로\n",
    "# 매개변수 pred_proba=None 추가\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},        F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경된 get_clf_eval() 호출 시 pred_proba_c1 추가\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict, pred_proba_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 0.4~0.6별로 정확도, 정밀도, 재현율, F1 스코어, ROC AUC 확인\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
